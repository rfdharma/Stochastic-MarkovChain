short_text <- df$full_text
# Split the text into words
text_term <- strsplit(short_text, split = " ") %>% unlist()
# Read the CSV file
df <- read.csv('result.csv', sep=';')
# Assuming 'full_text' is a column in the dataframe
short_text <- as.character(df$full_text)
# Split the text into words
text_term <- unlist(strsplit(short_text, split = " "))
# Read the CSV file
df <- read.csv('result.csv', sep=';')
# Assuming 'full_text' is a column in the dataframe
short_text <- as.character(df$full_text)
# Split the text into words
text_term <- unlist(strsplit(short_text, split = " "))
text_term
text_term
short_text
# Read the CSV file
df <- read.csv('result.csv', sep=';')
df
# a single sentence
short_text <- c("masih produksi kak mie dan beberapa snack seperti chimi ubi brownies crispy cassamo dan sola farm bisa kakak temui di indomaret maupun alfamart terdekat serta beberapa supermarket lainnya semoga membantu ya kak ðŸ˜ŠðŸ™ðŸ» terima kasih")
# split the sentence into words
text_term <- strsplit(short_text, split = " ") %>% unlist()
short_text
fit_markov <- markovchainFit(text_term, method = "laplace")
set.seed(123)
plot(fit_markov$estimate)
# Assuming you have the required libraries loaded
library(markovchain)
library(dplyr)
# Read the CSV file
df <- read.csv('result.csv', sep=';')
# Assuming 'full_text' is a column in the dataframe
short_text <- as.character(df$full_text)
# Split the text into words
text_term <- unlist(strsplit(short_text, split = " "))
# Fit a Markov chain model
fit_markov <- markovchainFit(text_term, method = "laplace")
df$text_term <- lapply(strsplit(df$full_text, split = " "), unlist)
# Read the CSV file
df <- read.csv('result.csv', sep=';')
df
df$text_term <- lapply(strsplit(df$x.full_text, split = " "), unlist)
df$text_term <- lapply(strsplit(df, split = " "), unlist)
columns(df)
col(df)
colnames(df)
df$text_term <- lapply(strsplit(df$X.full_text, split = " "), unlist)
# Fit a Markov chain model
fit_markov <- markovchainFit(df$text_term, method = "laplace")
df$text_term
# Assuming you have the required libraries loaded
library(markovchain)
library(dplyr)
# Read the CSV file
df <- read.csv('result.csv', sep=';')
df$text_term <- lapply(strsplit(df$X.full_text, split = " "), unlist)
# Fit a Markov chain model
fit_markov <- markovchainFit(df$text_term, method = "laplace")
# Read the CSV file
df <- read.csv('result.csv', sep=';')
# Split the text in the DataFrame into words
df$text_term <- strsplit(as.character(df$X.full_text), split = " ")
# Unlist the list of vectors into a single vector
text_states <- unlist(df$text_term)
# Fit a Markov chain model
fit_markov <- markovchainFit(text_states, method = "laplace")
# Set seed for reproducibility
set.seed(123)
# Plot the Markov chain model
plot(fit_markov$estimate)
# generate random sentence
for (i in 1:5) {
set.seed(i)
markovchainSequence(n = 7, # generate 7 next words
markovchain = fit_markov$estimate, # transition matrix
t0 = "the", include.t0 = T) %>%  # set the first word
# joint words
paste(collapse = " ") %>%
paste0(".") %>%
print()
}
# generate random sentence
for (i in 1:5) {
set.seed(i)
markovchainSequence(n = 7, # generate 7 next words
markovchain = fit_markov$estimate, # transition matrix
t0 = "mie", include.t0 = T) %>%  # set the first word
# joint words
paste(collapse = " ") %>%
paste0(".") %>%
print()
}
# generate random sentence
for (i in 1:3) {
set.seed(i)
markovchainSequence(n = 7, # generate 7 next words
markovchain = fit_markov$estimate, # transition matrix
t0 = "mie", include.t0 = T) %>%  # set the first word
# joint words
paste(collapse = " ") %>%
paste0(".") %>%
print()
}
# generate random sentence
for (i in 1:5) {
set.seed(i)
markovchainSequence(n = 7, # generate 7 next words
markovchain = fit_markov$estimate, # transition matrix
t0 = "mie", include.t0 = T) %>%  # set the first word
# joint words
paste(collapse = " ") %>%
paste0(".") %>%
print()
}
# generate random sentence
for (i in 1:5) {
set.seed(i)
markovchainSequence(n = 10, # generate 7 next words
markovchain = fit_markov$estimate, # transition matrix
t0 = "mie", include.t0 = T) %>%  # set the first word
# joint words
paste(collapse = " ") %>%
paste0(".") %>%
print()
}
predictive_text <- function(text, num_word){
text <- strsplit(text, " ") %>% unlist() %>% tail(1)
# exclude punctuation
punctuation <- which(fit_markov$estimate[ tolower(text), ] %>% names() %>% str_detect("[:punct:]"))
suggest <- fit_markov$estimate[ tolower(text), -punctuation] %>%
sort(decreasing = T) %>%
head(num_word)
suggest <- suggest[suggest > 0] %>%
names()
return(suggest)
}
predictive_text("mie", 10)
predictive_text <- function(text, num_word){
text <- strsplit(text, " ") %>% unlist() %>% tail(1)
# exclude punctuation
punctuation <- which(fit_markov$estimate[ tolower(text), ] %>% names() %>% str_detect("[:punct:]"))
suggest <- fit_markov$estimate[ tolower(text), -punctuation] %>%
sort(decreasing = T) %>%
head(num_word)
suggest <- suggest[suggest > 0] %>%
names()
return(suggest)
}
predictive_text("mie goreng", 10)
predictive_text <- function(text, num_word){
text <- strsplit(text, " ") %>% unlist() %>% tail(1)
# exclude punctuation
punctuation <- which(fit_markov$estimate[ tolower(text), ] %>% names() %>% str_detect("[:punct:]"))
suggest <- fit_markov$estimate[ tolower(text), -punctuation] %>%
sort(decreasing = T) %>%
head(num_word)
suggest <- suggest[suggest > 0] %>%
names()
return(suggest)
}
predictive_text("mie goreng", 5)
predictive_text <- function(text, num_word){
text <- strsplit(text, " ") %>% unlist() %>% tail(1)
# exclude punctuation
punctuation <- which(fit_markov$estimate[ tolower(text), ] %>% names() %>% str_detect("[:punct:]"))
suggest <- fit_markov$estimate[ tolower(text), -punctuation] %>%
sort(decreasing = T) %>%
head(num_word)
suggest <- suggest[suggest > 0] %>%
names()
return(suggest)
}
predictive_text("mie goreng", 2)
predictive_text <- function(text, num_word){
text <- strsplit(text, " ") %>% unlist() %>% tail(1)
# exclude punctuation
punctuation <- which(fit_markov$estimate[ tolower(text), ] %>% names() %>% str_detect("[:punct:]"))
suggest <- fit_markov$estimate[ tolower(text), -punctuation] %>%
sort(decreasing = T) %>%
head(num_word)
suggest <- suggest[suggest > 0] %>%
names()
return(suggest)
}
predictive_text("mie goreng dan mie rebus", 2)
predictive_text("mie goreng dan mie rebus", 3)
predictive_text <- function(text, num_word){
text <- strsplit(text, " ") %>% unlist() %>% tail(1)
# exclude punctuation
punctuation <- which(fit_markov$estimate[ tolower(text), ] %>% names() %>% str_detect("[:punct:]"))
suggest <- fit_markov$estimate[ tolower(text), -punctuation] %>%
sort(decreasing = T) %>%
head(num_word)
suggest <- suggest[suggest > 0] %>%
names()
return(suggest)
}
predictive_text("mie goreng dan mie rebus", 3)
predictive_text <- function(text, num_word){
text <- strsplit(text, " ") %>% unlist() %>% tail(1)
# exclude punctuation
punctuation <- which(fit_markov$estimate[ tolower(text), ] %>% names() %>% str_detect("[:punct:]"))
suggest <- fit_markov$estimate[ tolower(text), -punctuation] %>%
sort(decreasing = T) %>%
head(num_word)
suggest <- suggest[suggest > 0] %>%
names()
return(suggest)
}
predictive_text("mie goreng dan mie rebus", 5)
predictive_text <- function(text, num_word){
text <- strsplit(text, " ") %>% unlist() %>% tail(1)
# exclude punctuation
punctuation <- which(fit_markov$estimate[ tolower(text), ] %>% names() %>% str_detect("[:punct:]"))
suggest <- fit_markov$estimate[ tolower(text), -punctuation] %>%
sort(decreasing = T) %>%
head(num_word)
suggest <- suggest[suggest > 0] %>%
names()
return(suggest)
}
predictive_text("mie rebus", 5)
# generate random sentence
for (i in 1:5) {
set.seed(i)
markovchainSequence(n = 10, # generate 7 next words
markovchain = fit_markov$estimate, # transition matrix
t0 = "mie rebus", include.t0 = T) %>%  # set the first word
# joint words
paste(collapse = " ") %>%
paste0(".") %>%
print()
}
# generate random sentence
for (i in 1:5) {
set.seed(i)
markovchainSequence(n = 10, # generate 7 next words
markovchain = fit_markov$estimate, # transition matrix
t0 = "mie goreng", include.t0 = T) %>%  # set the first word
# joint words
paste(collapse = " ") %>%
paste0(".") %>%
print()
}
# generate random sentence
for (i in 1:5) {
set.seed(i)
markovchainSequence(n = 10, # generate 7 next words
markovchain = fit_markov$estimate, # transition matrix
t0 = "mie", include.t0 = T) %>%  # set the first word
# joint words
paste(collapse = " ") %>%
paste0(".") %>%
print()
}
# generate random sentence
for (i in 1:5) {
set.seed(i)
markovchainSequence(n = 5, # generate 7 next words
markovchain = fit_markov$estimate, # transition matrix
t0 = "mie", include.t0 = T) %>%  # set the first word
# joint words
paste(collapse = " ") %>%
paste0(".") %>%
print()
}
# generate random sentence
for (i in 1:5) {
set.seed(i)
markovchainSequence(n = 7, # generate 7 next words
markovchain = fit_markov$estimate, # transition matrix
t0 = "mie", include.t0 = T) %>%  # set the first word
# joint words
paste(collapse = " ") %>%
paste0(".") %>%
print()
}
# generate random sentence
for (i in 1:5) {
set.seed(i)
markovchainSequence(n = 6, # generate 7 next words
markovchain = fit_markov$estimate, # transition matrix
t0 = "mie", include.t0 = T) %>%  # set the first word
# joint words
paste(collapse = " ") %>%
paste0(".") %>%
print()
}
# generate random sentence
for (i in 1:5) {
set.seed(42)
markovchainSequence(n = 6, # generate 7 next words
markovchain = fit_markov$estimate, # transition matrix
t0 = "mie", include.t0 = T) %>%  # set the first word
# joint words
paste(collapse = " ") %>%
paste0(".") %>%
print()
}
# generate random sentence
for (i in 1:5) {
set.seed(i)
markovchainSequence(n = 6, # generate 7 next words
markovchain = fit_markov$estimate, # transition matrix
t0 = "mie", include.t0 = T) %>%  # set the first word
# joint words
paste(collapse = " ") %>%
paste0(".") %>%
print()
}
# generate random sentence
for (i in 1:5) {
set.seed(i)
markovchainSequence(n = 6, # generate 7 next words
markovchain = fit_markov$estimate, # transition matrix
t0 = "mie", include.t0 = T) %>%  # set the first word
# joint words
paste(collapse = " ") %>%
paste0(".") %>%
print()
}
predictive_text <- function(text, num_word){
text <- strsplit(text, " ") %>% unlist() %>% tail(1)
# exclude punctuation
punctuation <- which(fit_markov$estimate[ tolower(text), ] %>% names() %>% str_detect("[:punct:]"))
suggest <- fit_markov$estimate[ tolower(text), -punctuation] %>%
sort(decreasing = T) %>%
head(num_word)
suggest <- suggest[suggest > 0] %>%
names()
return(suggest)
}
predictive_text("mie rebus", 5)
predictive_text <- function(text, num_word){
text <- strsplit(text, " ") %>% unlist() %>% tail(1)
# exclude punctuation
punctuation <- which(fit_markov$estimate[ tolower(text), ] %>% names() %>% str_detect("[:punct:]"))
suggest <- fit_markov$estimate[ tolower(text), -punctuation] %>%
sort(decreasing = T) %>%
head(num_word)
suggest <- suggest[suggest > 0] %>%
names()
return(suggest)
}
predictive_text("mie", 5)
predictive_text <- function(text, num_word){
text <- strsplit(text, " ") %>% unlist() %>% tail(1)
# exclude punctuation
punctuation <- which(fit_markov$estimate[ tolower(text), ] %>% names() %>% str_detect("[:punct:]"))
suggest <- fit_markov$estimate[ tolower(text), -punctuation] %>%
sort(decreasing = T) %>%
head(num_word)
suggest <- suggest[suggest > 0] %>%
names()
return(suggest)
}
predictive_text("beli mie", 5)
predictive_text <- function(text, num_word){
text <- strsplit(text, " ") %>% unlist() %>% tail(1)
# exclude punctuation
punctuation <- which(fit_markov$estimate[ tolower(text), ] %>% names() %>% str_detect("[:punct:]"))
suggest <- fit_markov$estimate[ tolower(text), -punctuation] %>%
sort(decreasing = T) %>%
head(num_word)
suggest <- suggest[suggest > 0] %>%
names()
return(suggest)
}
predictive_text("beli mie di", 5)
predictive_text <- function(text, num_word){
text <- strsplit(text, " ") %>% unlist() %>% tail(1)
# exclude punctuation
punctuation <- which(fit_markov$estimate[ tolower(text), ] %>% names() %>% str_detect("[:punct:]"))
suggest <- fit_markov$estimate[ tolower(text), -punctuation] %>%
sort(decreasing = T) %>%
head(num_word)
suggest <- suggest[suggest > 0] %>%
names()
return(suggest)
}
predictive_text("beli mie di hari", 5)
predictive_text <- function(text, num_word){
text <- strsplit(text, " ") %>% unlist() %>% tail(1)
# exclude punctuation
punctuation <- which(fit_markov$estimate[ tolower(text), ] %>% names() %>% str_detect("[:punct:]"))
suggest <- fit_markov$estimate[ tolower(text), -punctuation] %>%
sort(decreasing = T) %>%
head(num_word)
suggest <- suggest[suggest > 0] %>%
names()
return(suggest)
}
predictive_text("beli mie di hari ini", 5)
predictive_text <- function(text, num_word){
text <- strsplit(text, " ") %>% unlist() %>% tail(1)
# exclude punctuation
punctuation <- which(fit_markov$estimate[ tolower(text), ] %>% names() %>% str_detect("[:punct:]"))
suggest <- fit_markov$estimate[ tolower(text), -punctuation] %>%
sort(decreasing = T) %>%
head(num_word)
suggest <- suggest[suggest > 0] %>%
names()
return(suggest)
}
predictive_text("beli", 5)
predictive_text <- function(text, num_word){
text <- strsplit(text, " ") %>% unlist() %>% tail(1)
# exclude punctuation
punctuation <- which(fit_markov$estimate[ tolower(text), ] %>% names() %>% str_detect("[:punct:]"))
suggest <- fit_markov$estimate[ tolower(text), -punctuation] %>%
sort(decreasing = T) %>%
head(num_word)
suggest <- suggest[suggest > 0] %>%
names()
return(suggest)
}
predictive_text("beli mie", 5)
predictive_text <- function(text, num_word){
text <- strsplit(text, " ") %>% unlist() %>% tail(1)
# exclude punctuation
punctuation <- which(fit_markov$estimate[ tolower(text), ] %>% names() %>% str_detect("[:punct:]"))
suggest <- fit_markov$estimate[ tolower(text), -punctuation] %>%
sort(decreasing = T) %>%
head(num_word)
suggest <- suggest[suggest > 0] %>%
names()
return(suggest)
}
predictive_text("beli mie goreng", 5)
predictive_text <- function(text, num_word){
text <- strsplit(text, " ") %>% unlist() %>% tail(1)
# exclude punctuation
punctuation <- which(fit_markov$estimate[ tolower(text), ] %>% names() %>% str_detect("[:punct:]"))
suggest <- fit_markov$estimate[ tolower(text), -punctuation] %>%
sort(decreasing = T) %>%
head(num_word)
suggest <- suggest[suggest > 0] %>%
names()
return(suggest)
}
predictive_text("beli mie goreng sama", 5)
predictive_text("beli mie goreng sama bakso", 5)
predictive_text("beli mie goreng sama bakso sorean", 5)
predictive_text("beli mie goreng sama bakso sorean kalau", 5)
predictive_text("beli mie goreng sama bakso sorean kalau lagi", 5)
predictive_text("beli mie goreng sama bakso sorean kalau lagi ada", 5)
predictive_text("beli mie goreng sama bakso sorean kalau lagi ada alternatif", 5)
predictive_text("beli mie goreng sama bakso sorean kalau lagi ada", 5)
predictive_text("beli mie goreng sama bakso sorean kalau lagi ada duit", 5)
predictive_text("beli mie goreng sama bakso sorean kalau lagi ada duit dan", 5)
predictive_text("beli mie goreng sama bakso sorean kalau lagi ada duit dan bahan", 5)
predictive_text("beli mie goreng sama bakso sorean kalau lagi ada duit dan bahan nder", 5)
# generate random sentence
for (i in 1:5) {
set.seed(i)
markovchainSequence(n = 6, # generate 7 next words
markovchain = fit_markov$estimate, # transition matrix
t0 = "mie", include.t0 = T) %>%  # set the first word
# joint words
paste(collapse = " ") %>%
paste0(".") %>%
print()
}
predictive_text <- function(text, num_word){
text <- strsplit(text, " ") %>% unlist() %>% tail(1)
# exclude punctuation
punctuation <- which(fit_markov$estimate[ tolower(text), ] %>% names() %>% str_detect("[:punct:]"))
suggest <- fit_markov$estimate[ tolower(text), -punctuation] %>%
sort(decreasing = T) %>%
head(num_word)
suggest <- suggest[suggest > 0] %>%
names()
return(suggest)
}
predictive_text <- function(text, num_word){
text <- strsplit(text, " ") %>% unlist() %>% tail(1)
# exclude punctuation
punctuation <- which(fit_markov$estimate[ tolower(text), ] %>% names() %>% str_detect("[:punct:]"))
suggest <- fit_markov$estimate[ tolower(text), -punctuation] %>%
sort(decreasing = T) %>%
head(num_word)
suggest <- suggest[suggest > 0] %>%
names()
return(suggest)
}
# generate random sentence
for (i in 1:5) {
set.seed(i)
markovchainSequence(n = 6, # generate 7 next words
markovchain = fit_markov$estimate, # transition matrix
t0 = "mie", include.t0 = T) %>%  # set the first word
# joint words
paste(collapse = " ") %>%
paste0(".") %>%
print()
}
predictive_text("mie", 5)
predictive_text("mie", 10)
predictive_text("mie", 5)
predictive_text("mie yang", 5)
predictive_text("mie yang terbaik", 5)
predictive_text("mie yang terbaik untk", 5)
predictive_text("mie yang terbaik untuk", 5)
predictive_text("mie yang terbaik untuk menyehatkan", 5)
predictive_text("mie yang terbaik untuk menyehatkan masyarakat", 5)
predictive_text("mie yang terbaik untuk menyehatkan masyarakat indonesia", 5)
predictive_text("mie yang terbaik untuk menyehatkan masyarakat indonesia dengan", 5)
predictive_text("mie yang terbaik untuk menyehatkan masyarakat indonesia dengan varian", 5)
predictive_text("mie yang terbaik untuk menyehatkan masyarakat indonesia dengan varian baru", 5)
